# Application Settings
APP_NAME="AI Universal Knowledge Ingestion System"
APP_VERSION="1.0.0"
DEBUG=False
HOST=0.0.0.0
PORT=8000

# File Upload Settings
MAX_FILE_SIZE_MB=100
MAX_BATCH_FILES=10

# Ollama LLM Settings
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b
OLLAMA_TIMEOUT=120

# Generation Parameters
DEFAULT_TEMPERATURE=0.1
TOP_P=0.9
MAX_TOKENS=1000
CONTEXT_WINDOW=8192

# OpenAI Settings (Optional - for alternative LLM)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Embedding Settings
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DIMENSION=384
EMBEDDING_DEVICE=cpu
EMBEDDING_BATCH_SIZE=32

# Chunking Settings
FIXED_CHUNK_SIZE=512
FIXED_CHUNK_OVERLAP=25
SEMANTIC_BREAKPOINT_THRESHOLD=0.80
PARENT_CHUNK_SIZE=2048
CHILD_CHUNK_SIZE=512
SMALL_DOC_THRESHOLD=1000
LARGE_DOC_THRESHOLD=500000

# Retrieval Settings
TOP_K_RETRIEVE=10
TOP_K_FINAL=5
FAISS_NPROBE=10
VECTOR_WEIGHT=0.6
BM25_WEIGHT=0.4
BM25_K1=1.5
BM25_B=0.75
ENABLE_RERANKING=True
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Cache Settings
ENABLE_CACHE=True
CACHE_TYPE=memory
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# Redis Settings (if using Redis cache)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Logging Settings
LOG_LEVEL=INFO
LOG_DIR=logs
LOG_ROTATION=500 MB
LOG_RETENTION=30 days

# RAGAS Evaluation Settings
ENABLE_RAGAS=True
RAGAS_ENABLE_GROUND_TRUTH=False
RAGAS_EVALUATION_TIMEOUT=60
RAGAS_BATCH_SIZE=10

# Performance Settings
MAX_WORKERS=4
ASYNC_BATCH_SIZE=10

# Security Settings
ENABLE_AUTH=False
SECRET_KEY=change-this-in-production-to-a-secure-random-string